<div align="center">
  <h1>ğŸ <strong>Swarm</strong> â€“ Bittensor Drone autopilot Subnet ğŸ</h1>
  <img src="swarm/assets/Swarm2.png" alt="Swarm"  width="300">
  <p>
    <a href="docs/miner.md">ğŸš€ Miner guide</a> &bull;
    <a href="docs/validator.md">ğŸ” Validator guide</a> &bull;
    <a href="docs/roadmap.md">ğŸ” Roadmap</a> &bull;
    <a href="https://x.com/SwarmSubnet">ğŸ¦ Follow us on X</a> &bull;
    <a href="https://discord.com/channels/799672011265015819/1385341501130801172">ğŸ’¬ Join us on Discord</a>
  </p>
</div>

## ğŸ” Overview
Swarm is a **Bittensor subnet engineered to enable decentralized autonomous drone flight**.

Validators create synthetic "map tasks" and evaluate minerâ€‘supplied **preâ€‘trained RL policies** inside a PyBullet physics simulator.  

Miners that produce fast and *successful* policies earn the highest rewards

**Why OS drone flying?**

- Open-sourcing flight algorithms isn't just idealism â€“ it is a practical route to safer, cheaper and more accountable drones, and it prevents the future of aerial autonomy from being locked behind half a dozen NDAs

- Our ambition is to establish Swarm miners as the **goâ€‘to control intelligence for microâ€‘drone navigation** in research and industry.

---
## âš™ï¸ Subnet Mechanics

### ğŸ§‘â€ğŸ« Validator

- Generates unique MapTasks  
- Evaluates policies headâ€‘less and validates them
- Assigns weights proportional to the final reward score

### â›ï¸ Miner

- Provides preâ€‘trained RL policies that are evaluated on secret tasks.  
- Any framework is allowed â€“ Stable Baselines 3, custom PyTorch, etc.  
- Must export models in compatible format for validator evaluation.

---

## Swarm Core components

| Component             | Purpose                           | Key points (code refs)                                                      |
|-----------------------|-----------------------------------|------------------------------------------------------------------------------|
| **MapTask**           | Internal validator task         | Random startâ†’goal pair, simulation timeâ€‘step `sim_dt`, hard time limit `horizon` (`swarm.protocol.MapTask`) |
| **PolicyRef**         | Model metadata                    | SHA256, framework, size (`swarm.protocol.PolicyRef`) |
| **Policy Evaluation** | RL model testing                 | Loads and runs policy on secret tasks (`swarm.validator.forward`) |
| **Reward**            | Maps outcome â†’ [0,1] score        | 0.50 Ã— success + 0.50 Ã— time (`swarm.validator.reward.flight_reward`) |

### Task generation

*Radial* goals 10â€“30 m away are sampled at random altitude; every mission is uniquely seeded and fully reproducible.

```python
# swarm/validator/task_gen.py
goal = rng.uniform(R_MIN, R_MAX)   # 10 m â‰¤ r â‰¤ 30 m
```

### Validation loop  
The validator:

1. Evaluates the provided policy
2. Tracks distanceâ€‘toâ€‘goal and hover duration
3. Scores the run and writes the weight to the chain

Here is an example image of our GUI!

<div align="center">
<img src="swarm/assets/drone_image.png" alt="Drone"  width="300">
</div>

---

## ğŸ¯ Incentive model

| Term        | Weight | Rationale                               |
|-------------|--------|-----------------------------------------|
| Success     | 0.50   | Reached + 5 s hover; safety first       |
| Time        | 0.50   | 1 âˆ’ t / horizon; encourages speed       |

---

## ğŸ¤ Contributing
PRs, issues and benchmark ideas are welcome!  

---

## ğŸ“œ License
Licensed under the MIT License â€“ see LICENSE.

Built with â¤ï¸ by the Swarm team.